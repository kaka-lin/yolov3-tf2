{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "yolov2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit",
      "language": "python",
      "name": "python_defaultSpec_1598344051507"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "329.969px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yP1hORfFp2sQ"
      },
      "source": [
        "# YOLOv3 - Tensorflow 2.0\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kaka-lin/yolov3-tf2/blob/master/yolov3_step_by_step.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag4pcut1eREt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/kaka-lin/yolov3-tf2\n",
        "%cd yolov3-tf2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HMpr7J5Zp2sR"
      },
      "source": [
        "## Import all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-04T09:15:12.153292Z",
          "start_time": "2019-10-04T09:15:10.721075Z"
        },
        "colab_type": "code",
        "id": "n9P6IN93p2sS",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, Input, Lambda,\n",
        "    LeakyReLU, UpSampling2D, \n",
        "    MaxPool2D, \n",
        "    concatenate, Add, ZeroPadding2D\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.losses import (\n",
        "    binary_crossentropy,\n",
        "    sparse_categorical_crossentropy\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ReduceLROnPlateau,\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    TensorBoard\n",
        ")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWE8QDJabwyX",
        "colab_type": "text"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v6R3i7mbwyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only use the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "    except RuntimeError as e:\n",
        "        # Visible devices must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SX1UkI92p2sW"
      },
      "source": [
        "## Download and Load Dataset\n",
        "    \n",
        "- [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)\n",
        "\n",
        "    - JPEGImages: 存放訓練和測試圖面\n",
        "    - Annatations: XML格式的標籤檔案，每個XML檔案都對應於Image資料夾的一張圖片"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfIT37uucDP0",
        "colab_type": "text"
      },
      "source": [
        "### Download the VOC2012 dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XE5PU8FcJ3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar -O ./data/VOCtrainval_11-May-2012.tar\n",
        "!tar xvf ./data/VOCtrainval_11-May-2012.tar --directory ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNWwBefHdqZV",
        "colab_type": "text"
      },
      "source": [
        "### Split dataset and transfer to `tfrecord`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YTXuDaBd6xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train\n",
        "!python3 voc2012.py \\\n",
        "    --data_dir ./data/VOCdevkit/VOC2012/ \\\n",
        "    --split train \\\n",
        "    --output_file ./data/voc2012_train.tfrecord\n",
        "\n",
        "# val\n",
        "!python3 voc2012.py \\\n",
        "    --data_dir ./data/VOCdevkit/VOC2012/ \\\n",
        "    --split val \\\n",
        "    --output_file ./data/voc2012_val.tfrecord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ncqzBDh1p2sW"
      },
      "source": [
        "### Load the tf.data.Dataset from TFRecord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-04T09:15:12.328334Z",
          "start_time": "2019-10-04T09:15:12.155225Z"
        },
        "colab_type": "code",
        "id": "0XDY5iTZp2sX",
        "colab": {}
      },
      "source": [
        "# load data from local\n",
        "#raw_train_dataset = tf.data.TFRecordDataset('./data/train_voc.tfrecord')\n",
        "\n",
        "raw_train_dataset = tf.data.TFRecordDataset('./data/voc2012_train.tfrecord')\n",
        "raw_val_dataset = tf.data.TFRecordDataset('./data/voc2012_val.tfrecord')\n",
        "raw_train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wQlRDcbzp2sa"
      },
      "source": [
        "## Explore the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BIdS-vSyp2sb"
      },
      "source": [
        "### 1. Parse VOC dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-04T09:15:12.387550Z",
          "start_time": "2019-10-04T09:15:12.330526Z"
        },
        "colab_type": "code",
        "id": "sjRaIMCKp2sb",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "for raw_train_data in raw_train_dataset.take(1):    \n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_train_data.numpy())  \n",
        "    #print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-04T09:15:12.727358Z",
          "start_time": "2019-10-04T09:15:12.389254Z"
        },
        "colab_type": "code",
        "id": "8pf2Mb8Ip2sd",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# Create a dictionary describing the features.\n",
        "image_feature_description = {\n",
        "    'filename': tf.io.FixedLenFeature([], tf.string),\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'classes': tf.io.VarLenFeature(tf.int64),\n",
        "    'x_mins': tf.io.VarLenFeature(tf.float32),\n",
        "    'y_mins': tf.io.VarLenFeature(tf.float32),\n",
        "    'x_maxes': tf.io.VarLenFeature(tf.float32),\n",
        "    'y_maxes': tf.io.VarLenFeature(tf.float32),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "def parse_tf_example(example_proto):\n",
        "    # Parse the input tf.Example proto using the dictionary above.\n",
        "    parsed_example = tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "    \n",
        "    x_train = tf.image.decode_jpeg(parsed_example['image_raw'], channels=3)\n",
        "    #x_train = tf.image.resize(x_train, (416, 416)) # yolov3 - input size\n",
        "    #x_train /= 255.\n",
        "    \n",
        "    width = tf.cast(parsed_example['width'], tf.float32)\n",
        "    height = tf.cast(parsed_example['height'], tf.float32)\n",
        "    \n",
        "    labels = tf.sparse.to_dense(parsed_example['classes'])\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    \n",
        "    xmin = tf.sparse.to_dense(parsed_example['x_mins'])\n",
        "    ymin = tf.sparse.to_dense(parsed_example['y_mins'])\n",
        "    xmax = tf.sparse.to_dense(parsed_example['x_maxes'])\n",
        "    ymax = tf.sparse.to_dense(parsed_example['y_maxes'])\n",
        "    \n",
        "    y_train = tf.stack([xmin,ymin,\n",
        "                        xmax,ymax,\n",
        "                        labels], axis=1)\n",
        "    \n",
        "    return x_train, y_train\n",
        "\n",
        "train_dataset = raw_train_dataset.map(parse_tf_example)\n",
        "val_dataset = raw_val_dataset.map(parse_tf_example)\n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-k3YWwU6p2sg"
      },
      "source": [
        "### 2. Show the data\n",
        "\n",
        "- (xmin, ymin, xmax, ymax): already normalization to 0~1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gtGRvRTJ1eu5",
        "colab": {}
      },
      "source": [
        "class_names = [c.strip() for c in open('./model_data/voc2012_classes.txt').readlines()]\n",
        "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
        "font_scale = 1\n",
        "font_thickness = 2\n",
        "\n",
        "for i, (x, y) in enumerate(train_dataset.take(3)):\n",
        "    img = x.numpy()\n",
        "    height, width = tf.shape(img)[0].numpy(), tf.shape(img)[1].numpy()\n",
        "    \n",
        "    for xmin, ymin, xmax, ymax, label in y.numpy():\n",
        "        left = (xmin * width).astype('int32')\n",
        "        top = (ymin * height).astype('int32')\n",
        "        right = (xmax * width).astype('int32')\n",
        "        bottom = (ymax * height).astype('int32')\n",
        "        label = class_names[int(label)]\n",
        "    \n",
        "        # cv2.rectangle(image, (left, top), (right, bottom), color, thickness)\n",
        "        cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "        cv2.putText(img, '{} {:.4f}'.format(label, 1.0000), (left, int(top - 4)), \n",
        "                    font_face, font_scale, (255, 0, 0), font_thickness, cv2.LINE_AA)\n",
        "    \n",
        "    f, (ax1) = plt.subplots(1, 1, figsize=(8,8))\n",
        "    f.subplots_adjust(hspace = .2, wspace = .05)\n",
        "    \n",
        "    ax1.imshow(img)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9QhgGgcOsm_G"
      },
      "source": [
        "## YOLOv3 Model's setting and parameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5NkacWXjpUZ",
        "colab": {}
      },
      "source": [
        "# anchor boxes\n",
        "YOLO_ANCHORS = np.array(\n",
        "    [(10, 13), (16, 30), (33, 23), \n",
        "     (30, 61), (62, 45), (59, 119),\n",
        "     (116, 90), (156, 198), (373, 326)], np.float32) / 416\n",
        "\n",
        "YOLO_ANCHORS_MASKS = np.array([[6, 7, 8],\n",
        "                               [3, 4, 5],\n",
        "                               [0, 1, 2]])\n",
        "\n",
        "num_max_box = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0VRLA0kGp2sm"
      },
      "source": [
        "## Preprocess the dataset\n",
        "\n",
        "- images: resize to (416, 416)\n",
        "- labels: `(xmin, ymi, xmax, ymax, class)` -> `(grid, grid, (bx, by, bw, bh, class))`\n",
        "\n",
        "- max ture boxes: 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "ZJ-EBBUzbwy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def transform_bboxes_for_output(y_true, grid_size, anchor_idxs, best_anchor_idx):\n",
        "    # y_true: (max_boxes, [x, y, w, h, classes])\n",
        "    N = tf.shape(y_true)[0]\n",
        "  \n",
        "    # y_true_out: (grid, grid, anchors, [x, y, w, h, obj, class])\n",
        "    y_true_out = tf.zeros(\n",
        "        (grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
        "    \n",
        "    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
        "    \n",
        "    indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
        "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
        "    \n",
        "    # Find which grid includes the center of object\n",
        "    #boxes_xy = y_true[..., 0:2]\n",
        "    #grid_xy = tf.cast(boxes_xy // (1 / grid_size), tf.int32)\n",
        "\n",
        "    for i in range(N):\n",
        "        if tf.equal(y_true[i][0], 0):\n",
        "            continue\n",
        "        \n",
        "        anchor_eq = tf.equal(\n",
        "            anchor_idxs, best_anchor_idx[i][0])\n",
        "        \n",
        "        if tf.reduce_any(anchor_eq):\n",
        "            # Find which grid includes the center of object\n",
        "            boxes_xy = y_true[i][0:2]\n",
        "            grid_xy = tf.cast(boxes_xy // (1 / grid_size), tf.int32)\n",
        "            \n",
        "            anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
        "\n",
        "            indices = indices.write(i, [grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
        "            updates = updates.write(i, [y_true[i][0], y_true[i][1], y_true[i][2], y_true[i][3], 1, y_true[i][4]])\n",
        "        \n",
        "    #tf.print(\"indices: \", indices.stack())\n",
        "    #tf.print(\"updates: \", updates.stack())\n",
        "    \n",
        "    return tf.tensor_scatter_nd_update(\n",
        "        y_true_out, indices.stack(), updates.stack())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8v9u1eOh1evK",
        "colab": {}
      },
      "source": [
        "def transform_bboxes(y_train, anchors, anchor_masks, image_size=416):\n",
        "    \"\"\"Area of anchor.\"\"\"\n",
        "    # anchors shape: (9, 2)\n",
        "    # Note: normalization anchors to 0~1 (anchors / 416)\n",
        "    #       -> anchors and boxes_wh are moved to origin point\n",
        "    #       -> we can conveniently find the minimum \n",
        "    #          between anchors and boxes_wh to find the intersection area.\n",
        "    anchors = tf.cast(anchors, tf.float32)\n",
        "    anchor_area = anchors[..., 0] * anchors[..., 1] # (9,)\n",
        "    \n",
        "    # y_train shape: (N, (x, y, w, h, classes))\n",
        "    boxes_wh = y_train[..., 2:4] # (N, 2)\n",
        "    \n",
        "    # expand dimension for compare with anchor\n",
        "    boxes_wh = tf.tile(tf.expand_dims(boxes_wh, -2),\n",
        "                     (1, tf.shape(anchors)[0], 1)) # (N, 9, 2)\n",
        "    boxes_area = boxes_wh[..., 0] * boxes_wh[..., 1] # (N, 9)\n",
        "    \n",
        "    \"\"\"Find IOU between box shifted to origin and anchor box.\"\"\"    \n",
        "    intersection = tf.minimum(boxes_wh[..., 0], anchors[..., 0]) * \\\n",
        "        tf.minimum(boxes_wh[..., 1], anchors[..., 1]) # (N, 9)\n",
        "    iou = intersection / (boxes_area + anchor_area - intersection) # (N, 9)\n",
        "    \n",
        "    \"\"\"Find the best iou.\"\"\"\n",
        "    best_anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
        "    best_anchor_idx = tf.expand_dims(best_anchor_idx, -1) # (N, 1)\n",
        "    best_anchor_idx = tf.cast(best_anchor_idx, tf.int32)\n",
        "    \n",
        "    \"\"\"Find which grid includes the center of object.\"\"\"\n",
        "    y_outs = []\n",
        "    grid_size = image_size // 32\n",
        "\n",
        "    for anchor_idxs in anchor_masks:\n",
        "        y_outs.append(transform_bboxes_for_output(\n",
        "            y_train, grid_size, anchor_idxs, best_anchor_idx))\n",
        "        grid_size *=2\n",
        "\n",
        "    return tuple(y_outs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ygwedXn1p2sp",
        "colab": {}
      },
      "source": [
        "def preprocess_data(x_train, y_train, anchors, anchor_masks, size=416):\n",
        "    \"\"\"preprocess the data\"\"\"\n",
        "    # Resize the image data.\n",
        "    x_train = tf.image.resize(x_train, (size, size))\n",
        "    x_train /= 255.\n",
        "    \n",
        "    # Box preprocessing.\n",
        "    # Origin boxes: (xmin, ymi, xmax, ymax, classes)\n",
        "    boxes = tf.reshape(y_train, [-1,5])\n",
        "    boxes_xy = 0.5 * (boxes[:, 2:4] + boxes[:, 0:2])\n",
        "    boxes_wh = boxes[:, 2:4] - boxes[:, 0:2]\n",
        "    # New boxes: (x_center, y_center, w, h, classes)\n",
        "    new_boxes = tf.concat((boxes_xy, boxes_wh, boxes[:, 4:]), axis=-1)\n",
        "    \n",
        "    \"\"\"Add zero pad for training \n",
        "    \n",
        "    paddings = [[row_top, row_bottom], [col_left, col_right]]\n",
        "    \"\"\"\n",
        "    paddings = [[0, num_max_box - tf.shape(new_boxes)[0]], [0, 0]] \n",
        "    new_y_train = tf.pad(new_boxes, paddings)\n",
        "    \n",
        "    new_y_train = transform_bboxes(new_y_train, anchors, anchor_masks)\n",
        "    \n",
        "    return x_train, new_y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iGevvDpJp2sr",
        "colab": {}
      },
      "source": [
        "# Use deep copy()\n",
        "anchors = YOLO_ANCHORS\n",
        "anchor_masks = YOLO_ANCHORS_MASKS\n",
        "\n",
        "train_dataset_2 = train_dataset.map(lambda x, y: (\n",
        "    preprocess_data(x, y, anchors, anchor_masks)))\n",
        "val_dataset_2 = val_dataset.map(lambda x, y: (\n",
        "    preprocess_data(x, y, anchors, anchor_masks)))\n",
        "\n",
        "train_dataset_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JDQG3lVit5nX"
      },
      "source": [
        "### Show the result of the dataset after preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab_type": "code",
        "id": "6qd91E7p1evT",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "for x, y_outs in train_dataset_2.take(3):\n",
        "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 30))\n",
        "    f.subplots_adjust(hspace = .2, wspace = .05)\n",
        "    axs = (ax1, ax2, ax3)\n",
        "    \n",
        "    for anchor_box_idx, y in enumerate(y_outs):\n",
        "        img = x.numpy()\n",
        "        img = np.array(img * 255, dtype=np.uint8)\n",
        "        true_boxes = y.numpy()\n",
        "\n",
        "        # Custom (rgb) grid color and object color\n",
        "        colors = [(255,0,0), (0,255,0), (0,0,255)]\n",
        "        grid_color = [255, 255, 255] # (255,255,255)\n",
        "\n",
        "        # Plot grid box\n",
        "        # Modify the image to include the grid\n",
        "        dowsample_size = 32 // pow(2, anchor_box_idx)\n",
        "        dx, dy = (dowsample_size, dowsample_size) # downsamples the input by 32\n",
        "        img[:,::dy,:] = grid_color\n",
        "        img[::dx,:,:] = grid_color\n",
        "\n",
        "        # Plot anchor box\n",
        "        anchor_exist = tf.not_equal(true_boxes[:, :, :, 0], 0)\n",
        "        anchor_boxes_idx = tf.cast(tf.where(anchor_exist), tf.int32)\n",
        "        for dy, dx, anchor_idx in anchor_boxes_idx:\n",
        "            # 1. anchor box center\n",
        "            anchor_boxes_xy = [(dx * dowsample_size, dy * dowsample_size)]\n",
        "            for i, box_xy in enumerate(anchor_boxes_xy):\n",
        "                cv2.circle(img, box_xy, 10, colors[anchor_idx], -1)\n",
        "\n",
        "            # 2. anchor box\n",
        "            anchor_box_wh = YOLO_ANCHORS[6 - anchor_box_idx * 3 + anchor_idx] * 416\n",
        "            anchor_box_wh_half = anchor_box_wh / 2.\n",
        "            bbox_mins = anchor_boxes_xy - anchor_box_wh_half\n",
        "            bbox_maxes = anchor_boxes_xy + anchor_box_wh_half\n",
        "\n",
        "            for i in range(len(bbox_mins)):\n",
        "                cv2.rectangle(img, (int(bbox_mins[i][0]), int(bbox_mins[i][1])), (int(bbox_maxes[i][0]), int(bbox_maxes[i][1])), colors[anchor_idx], 2)\n",
        "\n",
        "        # Plot true box\n",
        "        true_xy = true_boxes[..., 0:2] * 416\n",
        "        ture_wh = true_boxes[..., 2:4] * 416\n",
        "        true_wh_half = ture_wh / 2.\n",
        "        true_mins = tf.cast(true_xy - true_wh_half, tf.int32)\n",
        "        true_maxes = tf.cast(true_xy + true_wh_half, tf.int32)\n",
        "        true_bbox = tf.concat((true_mins, true_maxes), axis=-1)\n",
        "\n",
        "        for grid_y in true_bbox:\n",
        "            for grid_x in grid_y:\n",
        "                for box in grid_x:\n",
        "                    cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (255, 255, 0), 2)\n",
        "\n",
        "        axs[anchor_box_idx].imshow(img)\n",
        "    f.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mmBA3z-o1kbV"
      },
      "source": [
        "## Prepare the data for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guDrSChb1pnt",
        "colab": {}
      },
      "source": [
        "train_ds = train_dataset_2.shuffle(buffer_size=512).batch(16)\n",
        "train_ds = train_ds.prefetch(\n",
        "    buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "val_ds = val_dataset_2.batch(16)\n",
        "\n",
        "train_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "flm3kFz4p2s0"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "### Darknet53\n",
        "\n",
        "![](https://github.com/kaka-lin/yolov3-tf2/blob/master/model_data/darknet53.png?raw=1)\n",
        "\n",
        "### YOLOv3 Architecture\n",
        "\n",
        "![](https://github.com/kaka-lin/yolov3-tf2/blob/master/model_data/yolov3_5.jpg?raw=1)\n",
        "\n",
        "![](https://github.com/kaka-lin/yolov3-tf2/blob/master/model_data/yolov3_4.png?raw=1)\n",
        "\n",
        "![](https://github.com/kaka-lin/yolov3-tf2/blob/master/model_data/yolov3_3.png?raw=1)\n",
        "\n",
        "Image Source:\n",
        "\n",
        "1. [#011 TF YOLO V3 Object Detection in TensorFlow 2.0](http://datahacker.rs/tensorflow2-0-yolov3/)\n",
        "\n",
        "2. [Yolo：基於深度學習的物件偵測 (含YoloV3)](https://mropengate.blogspot.com/2018/06/yolo-yolov3.html)\n",
        "\n",
        "3. [What's new in YOLOv3?](https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AmEell-z1evm"
      },
      "source": [
        "### YOLOv3 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "fJkVbQy5bwzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
        "    \"\"\"\n",
        "    Make trainable=False freeze BN for real (the og version is sad)\n",
        "    \"\"\"\n",
        "    \n",
        "    def call(self, x, training=False):\n",
        "        if training is None:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          20,
          28
        ],
        "id": "A4rILw9jbwzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DarknetConv2D(x, filters, size, stride=1, batch_norm=True):\n",
        "    if stride == 1:\n",
        "        padding = 'same'\n",
        "    else:\n",
        "        # downsample\n",
        "        # padding=((top_pad, bottom_pad), (left_pad, right_pad))\n",
        "        x = ZeroPadding2D(((1, 0), (1, 0)))(x) # top left half-padding\n",
        "        padding = 'valid'\n",
        "    \n",
        "    x= Conv2D(filters=filters, kernel_size=size,\n",
        "              strides=(stride, stride), padding=padding,\n",
        "              use_bias=not batch_norm, \n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)\n",
        "    \n",
        "    if batch_norm:\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def DarknetResidual(x, filters):\n",
        "    prev= x\n",
        "    x = DarknetConv2D(x, filters // 2, 1)\n",
        "    x = DarknetConv2D(x, filters, 3)\n",
        "    x = Add()([prev, x])\n",
        "    return x\n",
        "\n",
        "# ResidualBlock\n",
        "def DarknetBlock(x, filters, num_blocks):\n",
        "    x = DarknetConv2D(x, filters, 3, stride=2)\n",
        "    for _ in range(num_blocks):\n",
        "        x = DarknetResidual(x, filters)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          13
        ],
        "id": "JQ4_YSKZbwzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def darknet_body(name=None):\n",
        "    x = inputs = Input([None, None, 3])\n",
        "    \n",
        "    # Darknet53\n",
        "    x = DarknetConv2D(x, 32, 3)\n",
        "    x = DarknetBlock(x, 64, num_blocks=1)\n",
        "    x = DarknetBlock(x, 128, num_blocks=2)\n",
        "    x = x_36 = DarknetBlock(x, 256, num_blocks=8) # skip connection\n",
        "    x = x_61 = DarknetBlock(x, 512, num_blocks=8) # conv + residual\n",
        "    x = DarknetBlock(x, 1024, num_blocks=4) # x_74\n",
        "    \n",
        "    return Model(inputs, (x_36, x_61, x), name=name)\n",
        "\n",
        "def yolo_body(filters, name=None):\n",
        "    def yolo_conv(x_in):\n",
        "        if isinstance(x_in, tuple):\n",
        "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
        "            x, x_skip = inputs\n",
        "            \n",
        "            # concat with skip connection\n",
        "            x = DarknetConv2D(x, filters, 1)\n",
        "            x = UpSampling2D(2)(x)\n",
        "            x = concatenate([x, x_skip])\n",
        "        else:\n",
        "            x = inputs = Input(x_in.shape[1:])\n",
        "        \n",
        "        x = DarknetConv2D(x, filters, 1)\n",
        "        x = DarknetConv2D(x, filters * 2, 3)\n",
        "        x = DarknetConv2D(x, filters, 1)\n",
        "        x = DarknetConv2D(x, filters * 2, 3)\n",
        "        x = DarknetConv2D(x, filters, 1)\n",
        "        return Model(inputs, x, name=name)(x_in)\n",
        "    return yolo_conv\n",
        "\n",
        "def yolo_output(filters, num_anchors, classes, name=None):\n",
        "    def yolo_output_conv(x_in):\n",
        "        x = inputs = Input(x_in.shape[1:])\n",
        "        x = DarknetConv2D(x, filters * 2, 3)\n",
        "        x = DarknetConv2D(x, (num_anchors * (classes + 5)), 1, batch_norm=False)\n",
        "        # output\n",
        "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], \n",
        "                                            num_anchors, classes + 5)))(x)\n",
        "        return Model(inputs, x, name=name)(x_in)\n",
        "    return yolo_output_conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "C3b4MWDNbwzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Yolov3(size=None, channels=3, \n",
        "           anchors=YOLO_ANCHORS, masks=YOLO_ANCHORS_MASKS,\n",
        "           classes=80):    \n",
        "    x = inputs = Input([size, size, channels], name='input')\n",
        "    \n",
        "    # Darknet53\n",
        "    '''\n",
        "    x = DarknetConv2D(x, 32, 3)\n",
        "    x = DarknetBlock(x, 64, num_blocks=1)\n",
        "    x = DarknetBlock(x, 128, num_blocks=2)\n",
        "    x = x_36 = DarknetBlock(x, 256, num_blocks=8) # skip connection\n",
        "    x = x_61 = DarknetBlock(x, 512, num_blocks=8) # conv + residual\n",
        "    x = DarknetBlock(x, 1024, num_blocks=4) # x_74\n",
        "    '''\n",
        "    x_36, x_61, x = darknet_body(name='yolo_darknet')(x)\n",
        "    \n",
        "    ##############################################################################\n",
        "    # Yolo Body\n",
        "    '''\n",
        "    x = DarknetConv2D(x, 512, 1)\n",
        "    x = DarknetConv2D(x, 1024, 3)\n",
        "    x = DarknetConv2D(x, 512, 1)\n",
        "    x = DarknetConv2D(x, 1024, 3)\n",
        "    x = x_79 = DarknetConv2D(x, 512, 1)\n",
        "    \n",
        "    # Yolo Output 1. 13x13x(anchor*(classes+5)\n",
        "    x = DarknetConv2D(x, 1024, 3)\n",
        "    x = DarknetConv2D(x, (num_anchors * (classes + 5)), 1, batch_norm=False)\n",
        "    output_0 = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], \n",
        "                                               num_anchors, classes + 5)))(x)\n",
        "    '''\n",
        "    x = yolo_body(512, name='yolo_conv_0')(x)\n",
        "    output_0 = yolo_output(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
        "                           \n",
        "    ############################################################################## \n",
        "    '''\n",
        "    # 82, output_0\n",
        "    # 83, route -4 -> x_79\n",
        "    # x_79 upsample + x_61\n",
        "    x = DarknetConv2D(x_79, 256, 1) # x_84\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, x_61]) \n",
        "    \n",
        "    # Yolo Body\n",
        "    x = DarknetConv2D(x, 256, 1)\n",
        "    x = DarknetConv2D(x, 512, 3)\n",
        "    x = DarknetConv2D(x, 256, 1)\n",
        "    x = DarknetConv2D(x, 512, 3)\n",
        "    x = x_91 = DarknetConv2D(x, 256, 1) \n",
        "    \n",
        "    # Yolo Output 2. 26x26x(anchor*(classes+5)\n",
        "    x = DarknetConv2D(x, 512, 3)\n",
        "    x = DarknetConv2D(x, (num_anchors * (classes + 5)), 1, batch_norm=False)             \n",
        "    output_1 = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], \n",
        "                                               num_anchors, classes + 5)))(x)\n",
        "    '''\n",
        "    x = yolo_body(256, name='yolo_conv_1')((x, x_61))\n",
        "    output_1 = yolo_output(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
        "    \n",
        "    ##############################################################################  \n",
        "    '''\n",
        "    # 94, output_1\n",
        "    # 95. route -4 -> x_91\n",
        "    # x_91 upsample + x_36\n",
        "    x = DarknetConv2D(x_91, 128, 1) # x_92\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, x_36])\n",
        "    \n",
        "    # Yolo Body\n",
        "    x = DarknetConv2D(x, 128, 1)\n",
        "    x = DarknetConv2D(x, 256, 3)\n",
        "    x = DarknetConv2D(x, 128, 1)\n",
        "    x = DarknetConv2D(x, 256, 3)\n",
        "    x = x_91 = DarknetConv2D(x, 128, 1)\n",
        "    \n",
        "    # Yolo Output 3. 52x52x(anchor*(classes+5)\n",
        "    x = DarknetConv2D(x, 256, 3)\n",
        "    x = DarknetConv2D(x, (num_anchors * (classes + 5)), 1, batch_norm=False)\n",
        "    output_2 = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], \n",
        "                                               num_anchors, classes + 5)))(x)\n",
        "    '''\n",
        "    x = yolo_body(128, name='yolo_conv_2')((x, x_36))\n",
        "    output_2 = yolo_output(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
        "    \n",
        "    return Model(inputs, (output_0, output_1, output_2), name='yolov3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Y2J3Ze20bwzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Yolov3(416, classes=20)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cWe7R_FzKBnN"
      },
      "source": [
        "### Convert Darknet weights  to TensorFlow weights\n",
        "\n",
        "- Darknet weights (.weights) to TensorFlow weights (.ckpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ncr6Z8EiGVJ",
        "colab_type": "text"
      },
      "source": [
        "#### Download pre-trained Darknet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLi0EQyoiFYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O model_data/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-sET-wnbwze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "YOLOV3_LAYER_LIST = [\n",
        "    'yolo_darknet',\n",
        "    'yolo_conv_0',\n",
        "    'yolo_output_0',\n",
        "    'yolo_conv_1',\n",
        "    'yolo_output_1',\n",
        "    'yolo_conv_2',\n",
        "    'yolo_output_2',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab_type": "code",
        "id": "hpM-4TMHKBnP",
        "colab": {}
      },
      "source": [
        "def load_darknet_weights(model, weights_file):\n",
        "    with open(weights_file, 'rb') as wf:\n",
        "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "        layers = YOLOV3_LAYER_LIST\n",
        "        \n",
        "        for layer_name in layers:\n",
        "            sub_model = model.get_layer(layer_name)\n",
        "            for i, layer in enumerate(sub_model.layers):\n",
        "                if not layer.name.startswith('conv2d'):\n",
        "                    continue\n",
        "\n",
        "                # BatchNormalization layer\n",
        "                batch_norm = None    \n",
        "                if i + 1 < len(sub_model.layers) and \\\n",
        "                        sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
        "                    batch_norm = sub_model.layers[i + 1]\n",
        "                \n",
        "                print(\"{}/{} {}\".format(\n",
        "                    sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
        "\n",
        "                filters = layer.filters\n",
        "                kerner_size = layer.kernel_size[0]\n",
        "                input_dim = layer.input_shape[-1]\n",
        "\n",
        "                if batch_norm is None:\n",
        "                    conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "                else:\n",
        "                    # darknet [beta, gamma, mean, variance]\n",
        "                    bn_weights = np.fromfile(\n",
        "                        wf, dtype=np.float32, count=4*filters)\n",
        "                    # tf [gamma, beta, mean, variance]\n",
        "                    bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "\n",
        "                # darknet shape (out_dim, input_dim, height, width)\n",
        "                conv_shape = (filters, input_dim, kerner_size, kerner_size)\n",
        "                conv_weights = np.fromfile(\n",
        "                    wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "\n",
        "                # tf shape (height, width, in_dim, out_dim)\n",
        "                conv_weights = conv_weights.reshape(\n",
        "                    conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "                if batch_norm is None:\n",
        "                    layer.set_weights([conv_weights, conv_bias])\n",
        "                else:\n",
        "                    layer.set_weights([conv_weights])\n",
        "                    batch_norm.set_weights(bn_weights)\n",
        "\n",
        "            print(\"Completed!\")\n",
        "    print(\"Weights loaded!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab_type": "code",
        "id": "chz7yJPjKBnR",
        "colab": {}
      },
      "source": [
        "def convert_darknet_to_tensorflow():\n",
        "    darknet_weights_file = './model_data/yolov3.weights'\n",
        "    tensorflow_weights_file = './checkpoints/yolov3.tf'\n",
        "    convert_model = Yolov3()\n",
        "    load_darknet_weights(convert_model, darknet_weights_file)\n",
        "    convert_model.save_weights(tensorflow_weights_file)\n",
        "    print('Weights saved!')\n",
        "\n",
        "convert_darknet_to_tensorflow()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbdhCQfMhyF2",
        "colab_type": "text"
      },
      "source": [
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0MEgQRibwzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freeze_all(model, frozen=True):\n",
        "    model.trainable = not frozen\n",
        "    if isinstance(model, tf.keras.Model):\n",
        "        for l in model.layers:\n",
        "            freeze_all(l, frozen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MPYzYMebwzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pretrained model\n",
        "model_pretrained = Yolov3(416, classes=80)\n",
        "model_pretrained.load_weights('./checkpoints/yolov3.tf')\n",
        "\n",
        "model.get_layer('yolo_darknet').set_weights(\n",
        "    model_pretrained.get_layer('yolo_darknet').get_weights())\n",
        "\n",
        "# freeze darknet and fine tune other layers\n",
        "freeze_all(model.get_layer('yolo_darknet'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pc9VsZOf1evq"
      },
      "source": [
        "### YOLOv3 LOSS\n",
        "\n",
        "![](https://github.com/kaka-lin/yolov3-tf2/blob/master/model_data/loss.png?raw=1)\n",
        "\n",
        "Reference: [YOLO v3 物件偵測~論文整理](https://medium.com/%E7%A8%8B%E5%BC%8F%E5%B7%A5%E4%BD%9C%E7%B4%A1/yolo-v3-%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC-%E8%AB%96%E6%96%87%E6%95%B4%E7%90%86-11ee909430c8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab_type": "code",
        "id": "EXdtkd8kp2s7",
        "colab": {}
      },
      "source": [
        "def yolo_bboxes(pred, anchors, classes):\n",
        "    \"\"\" YOLO - bounding box formula\n",
        "    \n",
        "    bx = sigmoid(tx) + cx\n",
        "    by = sigmoid(ty) + cy\n",
        "    bw = pw * exp^(tw)\n",
        "    bh = ph * exp^(th)\n",
        "    Pr(obj) * IOU(b, object) = sigmoid(to) # confidence\n",
        "    \n",
        "    (tx, ty, tw, th, to) are the output of the model.\n",
        "    \"\"\"\n",
        "    # pred: (batch_size, grid, grid, anchors, (tx, ty, tw, th, conf, ...classes))\n",
        "    grid_size = tf.shape(pred)[1]\n",
        "\n",
        "    box_xy = tf.sigmoid(pred[..., 0:2])\n",
        "    box_wh = pred[..., 2:4]\n",
        "    box_confidence = tf.sigmoid(pred[..., 4:5])\n",
        "    box_class_probs = tf.sigmoid(pred[..., 5:])\n",
        "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
        "\n",
        "    # box_xy: (grid_size, grid_size, num_anchors, 2)\n",
        "    # grid: (grdid_siez, grid_size, 1, 2)\n",
        "    #       -> [0,0],[0,1],...,[0,12],[1,0],[1,1],...,[12,12]\n",
        "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
        "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
        "    \n",
        "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\n",
        "        tf.cast(grid_size, tf.float32)\n",
        "    box_wh = tf.exp(box_wh) * anchors\n",
        "    pred_bbox = tf.concat((box_xy, box_wh), axis=-1)\n",
        "\n",
        "    return pred_bbox, box_confidence, box_class_probs, pred_box"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab_type": "code",
        "id": "jCrqi6AJp2s-",
        "colab": {}
      },
      "source": [
        "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
        "    def yolo_loss(y_true, y_pred):\n",
        "        \"\"\"\"1. transform all pred outputs.\"\"\"\n",
        "        # y_pred: (batch_size, grid, grid, anchors, (tx, ty, tw, th, conf, ...cls))\n",
        "        pred_bbox, pred_confidence, pred_class_probs, pred_box = yolo_bboxes(\n",
        "            y_pred, anchors, classes)\n",
        "        pred_xy = pred_box[..., 0:2]\n",
        "        pred_wh = pred_box[..., 2:4]\n",
        "\n",
        "        \"\"\"2. transform all true outputs.\"\"\"\n",
        "        # y_true: (batch_size, grid, grid, anchors, (bx, by, bw, bh, conf, cls))\n",
        "        true_xy, true_wh, true_confidence, true_class = tf.split(\n",
        "            y_true, (2, 2, 1, 1), axis=-1)\n",
        "        true_boxes = tf.concat([true_xy, true_wh], axis=-1)\n",
        "        \n",
        "        # give higher weights to small boxes\n",
        "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
        "        \n",
        "        # Invert ture_boxes: multiplied by now grid size\n",
        "        grid_size = tf.shape(y_true)[1]\n",
        "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
        "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
        "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
        "            tf.cast(grid, tf.float32)\n",
        "        true_wh = tf.math.log(true_wh / anchors)\n",
        "        true_wh = tf.where(tf.math.is_inf(true_wh),\n",
        "                           tf.zeros_like(true_wh), true_wh)  # avoid log(0)=-inf\n",
        "        \n",
        "        \"\"\"3. true_box: remove noobject cell.\"\"\"\n",
        "        # true_confidence: cell has object or not\n",
        "        #                 0/1 mask for detectors in [conv_height, conv_width, num_anchors, 1]\n",
        "        # true_confidence_mask: [conv_height, conv_width, num_anchors]\n",
        "        true_conf_mask = tf.squeeze(true_confidence, -1)\n",
        "        \n",
        "        \"\"\"4. Calculate `coordinate loss`.\"\"\"  \n",
        "        xy_loss = box_loss_scale * true_conf_mask * \\\n",
        "                  tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
        "        wh_loss = box_loss_scale * true_conf_mask * \\\n",
        "                  tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
        "        \n",
        "        \"\"\"5. Calculate `classification loss`.\"\"\"\n",
        "        # square(one_hot(true_class) - pred_class_probs)\n",
        "        # TODO: use binary_crossentropy instead\n",
        "        #   - true_class:       13x13x3x1\n",
        "        #   - pred_class_probs: 13x13x3x20\n",
        "        classification_loss = true_conf_mask * sparse_categorical_crossentropy(\n",
        "                true_class, pred_class_probs)\n",
        "        \n",
        "        \"\"\"6. Calculate `confidence loss.`\n",
        "        \n",
        "        1. Find the IOU score of each predicted box with each ground truth box.\n",
        "        2. Find the Best IOU scores.\n",
        "        3. A confidence detector that this cell has object if IOU > threshold otherwise no object.\n",
        "        4. Calculate confidence loss.\n",
        "        \"\"\"\n",
        "        ############################################################################################################\n",
        "        # Reshape true_box: (N, grid, grid, num_anchors, 4) to (N, num_true_boxes, 4)  \n",
        "        true_boxes_flat = tf.boolean_mask(true_boxes, tf.cast(true_conf_mask, tf.bool))\n",
        "        \n",
        "        # broadcast shape: (N, grid, grid, num_anchors, num_true_boxes, (x, y, w, h))\n",
        "        true_boxes = tf.expand_dims(true_boxes, -2) # (N, 13, 13, 3, 1, 4)\n",
        "        true_boxes_flat = tf.expand_dims(true_boxes_flat, 0) # (1, num_true_boxes, 4)\n",
        "        new_shape = tf.broadcast_dynamic_shape(tf.shape(true_boxes), tf.shape(true_boxes_flat)) # (N, 13, 13, 3, num_true_boxes, 4)\n",
        "        \n",
        "        # reshape: (batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params)\n",
        "        true_boxes = tf.broadcast_to(true_boxes, new_shape)\n",
        "        true_xy = true_boxes[..., 0:2]\n",
        "        true_wh = true_boxes[..., 2:4] # (N, 13, 13, 5, num_true_boxes, 2)\n",
        "        \n",
        "        true_wh_half = true_wh / 2.\n",
        "        true_mins = true_xy - true_wh_half\n",
        "        true_maxes = true_xy + true_wh_half\n",
        "        \n",
        "        # Expand pred (x,y,w,h) to allow comparison with ground truth.\n",
        "        # (batch, conv_height, conv_width, num_anchors, 1, box_params)\n",
        "        pred_xy = pred_bbox[..., 0:2]\n",
        "        pred_wh = pred_bbox[..., 2:4]\n",
        "        pred_xy = tf.expand_dims(pred_xy, 4)\n",
        "        pred_wh = tf.expand_dims(pred_wh, 4)\n",
        "        \n",
        "        pred_wh_half = pred_wh / 2.\n",
        "        pred_mins = pred_xy - pred_wh_half\n",
        "        pred_maxes = pred_xy + pred_wh_half\n",
        "        \n",
        "        intersection_mins = tf.maximum(pred_mins, true_mins)\n",
        "        intersection_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "        intersection_wh = tf.maximum(intersection_maxes - intersection_mins, 0.)\n",
        "        intersection_areas = intersection_wh[..., 0] * intersection_wh[..., 1] # (-1, 13, 13, 3, num_true_boxes)\n",
        "        \n",
        "        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "        true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "        \n",
        "        \"\"\"6-1. Calculate IOU scores for each location.\"\"\"\n",
        "        union_areas = pred_areas + true_areas - intersection_areas\n",
        "        iou_scores = intersection_areas / union_areas # (-1, 13, 13, 3, num_true_boxes)\n",
        "        \n",
        "        \"\"\"6-2. Best IOU scores.\"\"\"\n",
        "        best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "        \n",
        "        \"\"\"6-3. Ignore mask.\"\"\"\n",
        "        # ignore false positive when iou is over threshold\n",
        "        ignore_mask = tf.cast(best_ious < ignore_thresh, tf.float32) # (-1, 13, 13, 3, 1)\n",
        "    \n",
        "        \"\"\"6-4. Confidence loss.\"\"\"\n",
        "        objects_loss = binary_crossentropy(true_confidence, pred_confidence)\n",
        "        confidence_loss = true_conf_mask * objects_loss + \\\n",
        "                          (1 - true_conf_mask) * ignore_mask * objects_loss\n",
        "        ############################################################################################################\n",
        "       \n",
        "        # 7. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
        "        xy_loss_sum = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
        "        wh_loss_sum = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
        "        confidence_loss_sum = tf.reduce_sum(confidence_loss, axis=(1, 2, 3))\n",
        "        classification_loss_sum = tf.reduce_sum(classification_loss, axis=(1, 2, 3))\n",
        "        \n",
        "        '''\n",
        "        tf.print(xy_loss_sum)\n",
        "        tf.print(wh_loss_sum)\n",
        "        tf.print(confidence_loss_sum)\n",
        "        tf.print(classification_loss_sum)\n",
        "        '''\n",
        "        \n",
        "        return (xy_loss_sum + wh_loss_sum + confidence_loss_sum + classification_loss_sum)\n",
        "    return yolo_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yMBg_5-309m_"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1_ph3DKlp2tB",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "yolo_loss = [YoloLoss(anchors[mask], classes=20)\n",
        "             for mask in anchor_masks]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2PShy_Vhp2tF",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "                     loss=yolo_loss,\n",
        "                     run_eagerly=False)\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(verbose=1),\n",
        "    EarlyStopping(patience=3, verbose=1),\n",
        "    ModelCheckpoint('checkpoints/yolov3_train_{epoch}.tf',\n",
        "                    verbose=1, save_weights_only=True),\n",
        "    TensorBoard(log_dir='logs')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfMi90Mu1JSB"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YSjw9FsOp2tM",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "                    epochs=10,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHNyFyRGbw0G",
        "colab_type": "text"
      },
      "source": [
        "### Save and Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0wVo_vvfOIG",
        "colab": {}
      },
      "source": [
        "# Save\n",
        "#tf.saved_model.save(model, path + \"/model_data\")\n",
        "model.save(\"./model_data/yolov3.h5\") \n",
        "\n",
        "# Load\n",
        "'''\n",
        "model = tf.keras.models.load_model(\"model_data/yolov3.h5\", \n",
        "                                   custom_objects={'loss': yolo_loss},\n",
        "                                   compile=False)\n",
        "'''                                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xhS5nbMbw0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yolo = Yolov3(classes=20)\n",
        "yolo.load_weights('./checkpoints/yolov3_train_8.tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkMxvv9s3YKA"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "91ifuyQClnyd"
      },
      "source": [
        "### YOLO Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ytvoc-WgOpdS",
        "colab": {}
      },
      "source": [
        "def yolo_boxes_to_corners(box_xy, box_wh):\n",
        "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
        "    box_mins = box_xy - (box_wh / 2.)\n",
        "    box_maxes = box_xy + (box_wh / 2.)\n",
        "\n",
        "    return tf.concat([\n",
        "        box_mins[..., 0:1],  # x_min\n",
        "        box_mins[..., 1:2],  # y_min\n",
        "        box_maxes[..., 0:1],  # x_max\n",
        "        box_maxes[..., 1:2],  # y_max  \n",
        "    ], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYl6DckUbw0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_boxes_and_scores(yolo_output, anchors, num_classes=20):\n",
        "    \"\"\"Process output layer\"\"\"\n",
        "    bbox, box_confidence, box_class_probs, pred_box = yolo_bboxes(yolo_output, anchors, num_classes)\n",
        "    \n",
        "    # Convert boxes to be ready for filtering functions.\n",
        "    box_xy = bbox[..., 0:2]\n",
        "    box_wh = bbox[..., 2:4]\n",
        "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
        "    boxes = tf.reshape(boxes, [-1, 4])\n",
        "    \n",
        "    # Compute box scores\n",
        "    box_scores = box_confidence * box_class_probs\n",
        "    box_scores = tf.reshape(box_scores, [-1, num_classes])\n",
        "    return boxes, box_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "colab_type": "code",
        "id": "s_PNRFU7lb8q",
        "colab": {}
      },
      "source": [
        "def yolo_non_max_suppression(boxes, box_scores, classes, \n",
        "                             max_boxes=10,\n",
        "                             score_threshold=0.5,\n",
        "                             iou_threshold=0.5):\n",
        "    \"\"\"Perform Score-filtering and Non-max suppression\n",
        "    \n",
        "    boexs: (10647, 4)\n",
        "    box_scores: (10647, num_classes)\n",
        "    # 10674 = (13*13 + 26*26 + 52*52) * 3(anchor)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a mask, same dimension as box_scores\n",
        "    mask = box_scores >= score_threshold\n",
        "\n",
        "    output_boxes = []\n",
        "    output_scores = []\n",
        "    output_classes = []\n",
        "\n",
        "    # Perform NMS for all classes\n",
        "    for c in range(classes):\n",
        "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
        "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
        "\n",
        "        selected_indices = tf.image.non_max_suppression(\n",
        "            class_boxes, class_box_scores, max_boxes, iou_threshold)\n",
        "\n",
        "        class_boxes = tf.gather(class_boxes, selected_indices)\n",
        "        class_box_scores = tf.gather(class_box_scores, selected_indices)\n",
        "        classes = tf.ones_like(class_box_scores, 'int32') * c\n",
        "\n",
        "        output_boxes.append(class_boxes)\n",
        "        output_scores.append(class_box_scores)\n",
        "        output_classes.append(classes)\n",
        "    \n",
        "    output_boxes = tf.concat(output_boxes, axis=0)\n",
        "    output_scores = tf.concat(output_scores, axis=0)\n",
        "    output_classes = tf.concat(output_classes, axis=0)\n",
        "    \n",
        "    return output_scores, output_boxes, output_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BcHaoG5FONDy",
        "colab": {}
      },
      "source": [
        "def yolo_eval(yolo_outputs, \n",
        "              image_shape=(416, 416), \n",
        "              classes=20, \n",
        "              max_boxes=10, \n",
        "              score_threshold=0.5, \n",
        "              iou_threshold=0.5):\n",
        "    # Retrieve outputs of the YOLO model.\n",
        "    for i in range(0,3):\n",
        "        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[i], anchors[6-3*i:9-3*i], classes)\n",
        "        if i == 0:\n",
        "            boxes, box_scores = _boxes, _box_scores\n",
        "        else:\n",
        "            boxes = tf.concat([boxes, _boxes], axis=0)\n",
        "            box_scores = tf.concat([box_scores, _box_scores], axis=0)\n",
        "    \n",
        "    # Perform Score-filtering and Non-max supression.\n",
        "    scores, boxes, classes = yolo_non_max_suppression(boxes, box_scores, \n",
        "                                                      classes, max_boxes, \n",
        "                                                      score_threshold, iou_threshold)\n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WA-3KuDnljX5"
      },
      "source": [
        "### Other Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZPn-BJN8RVYF",
        "colab": {}
      },
      "source": [
        "def scale_boxes(boxes, image_shape):\n",
        "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
        "    height, width = image_shape\n",
        "    image_dims = tf.stack([width, height, width, height])\n",
        "    image_dims = tf.cast(tf.reshape(image_dims, [1, 4]), tf.float32)\n",
        "    boxes = boxes * image_dims\n",
        "    return boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2uBcSiAaSiVc",
        "colab": {}
      },
      "source": [
        "def draw_outputs(image, outputs, class_names):\n",
        "    h, w, _ = image.shape\n",
        "    scores, boxes, classes = outputs\n",
        "    boxes = scale_boxes(boxes, (h, w))\n",
        "\n",
        "    font_face = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
        "    font_scale = 2\n",
        "    font_thickness = 2\n",
        "    \n",
        "    for i in range(scores.shape[0]):\n",
        "        left, top, right, bottom = boxes[i]\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(h, np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(w, np.floor(right + 0.5).astype('int32'))\n",
        "        label = class_names[int(classes[i])]\n",
        "        score = scores[i].numpy()\n",
        "\n",
        "        # colors: RGB\n",
        "        cv2.rectangle(image, (left, top), (right, bottom), (255, 0, 0), font_thickness)\n",
        "        cv2.putText(image, '{} {:.4f}'.format(label, score), (left, int(top - 4)),\n",
        "                    font_face, font_scale, (0, 0, 255), font_thickness, cv2.LINE_AA)\n",
        "        \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C_xVcdAjl5Kk"
      },
      "source": [
        "### Start detect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yl2DFSE-aVKc",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# 選一張圖像\n",
        "img_filepath = \"./data/street.jpg\"\n",
        "\n",
        "# 使用OpenCV讀入圖像\n",
        "images = cv2.imread(img_filepath) # 載入圖像\n",
        "images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 進行圖像輸入的前處理\n",
        "input_image = cv2.resize(images, (416, 416)) # 修改輸入圖像大小來符合模型的要求\n",
        "input_image = input_image / 255. # 進行圖像歸一處理\n",
        "input_image = np.expand_dims(input_image, 0)  # 增加 batch dimension\n",
        "\n",
        "# 進行圖像偵測\n",
        "yolo_outputs = yolo.predict(input_image)\n",
        "scores, boxes, classes = yolo_eval(\n",
        "    yolo_outputs, \n",
        "    score_threshold=0.2,\n",
        "    iou_threshold=0.2)\n",
        "\n",
        "class_names = [c.strip() for c in open('./model_data/voc2012_classes.txt').readlines()]\n",
        "print(\"detections:\")\n",
        "for i in range(scores.shape[0]):\n",
        "    print(\"\\t{}, {}, {}\".format(\n",
        "        class_names[int(classes[i])], scores[i], boxes[i]\n",
        "    ))\n",
        "\n",
        "# Draw bounding boxes on the image file\n",
        "image = draw_outputs(images, (scores, boxes, classes), class_names)\n",
        "\n",
        "# Save\n",
        "cv2.imwrite(\"./model_data/output.jpg\", image)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVzuuec4bw0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}